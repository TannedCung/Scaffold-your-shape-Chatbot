# LangChain configuration
LANGCHAIN_API_KEY=your_langchain_api_key_here
LANGCHAIN_PROJECT=pili-exercise-chatbot

# External service URLs
EXERCISE_SERVICE_URL=http://192.168.1.10:8888/v1

# LLM Configuration
# Options: "openai", "ollama", "vllm", "local"
# LLM_PROVIDER=openai

# OpenAI configuration
# OPENAI_API_KEY=your_openai_api_key_here
# OPENAI_MODEL=gpt-3.5-turbo

# Local LLM configuration (for Ollama, vLLM, etc.)
# LOCAL_LLM_BASE_URL=http://192.168.1.10:8888
# LOCAL_LLM_MODEL=llama2
# LOCAL_LLM_API_KEY=  # Leave empty for Ollama, set for vLLM if auth required

# Example configurations for different providers:
# 
# For Ollama (default port 11434):
# LLM_PROVIDER=ollama
# LOCAL_LLM_BASE_URL=http://localhost:11434
# LOCAL_LLM_MODEL=llama2
#
# For vLLM (custom port):
LLM_PROVIDER=vllm
LOCAL_LLM_BASE_URL=http://192.168.1.10:8888/v1
LOCAL_LLM_MODEL=Qwen/Qwen3-32B-AWQ
#
# For other OpenAI-compatible APIs:
# LLM_PROVIDER=local
# LOCAL_LLM_BASE_URL=http://your-api-url:port/v1
# LOCAL_LLM_MODEL=your-model-name
# LOCAL_LLM_API_KEY=your-api-key-if-required 